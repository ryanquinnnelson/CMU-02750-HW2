{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imposed-solid",
   "metadata": {},
   "source": [
    "## Question 1. ZLG algorithm implementation (50 points)\n",
    "**You are to implement the ZLG algorithm for this problem.**\n",
    "- **We will use a subset of multiclass data where the label is a protein subcellular localization.**\n",
    "- **The 8 features are extracted from the protein sequence.**\n",
    "- **For this problem we are only using points with labels `MIT` or `NUC`.**\n",
    "- **A total of 892 data points have labels `MIT` (244) or `NUC` (429). We start with the labels of only the first 200 data points (set `Y_k`). The other 792 points are in `Y_u`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-provincial",
   "metadata": {},
   "source": [
    "**First, read the paper and answer the following questions.**\n",
    "#### 1. What is the idea behind the ZLG algorithm (5 points)?\n",
    "#### 2. What are the assumptions behind the ZLG algorithm (5 points)?\n",
    "#### 3. What are the pros and cons of the ZLG algorithm (5points)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-sugar",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hairy-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-significance",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "desperate-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (673, 9)\n",
      "unique labels ['MIT' 'NUC']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2    X3    X4   X5   X6    X7    X8 Label\n",
       "0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n",
       "1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n",
       "2  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n",
       "3  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n",
       "4  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "print('shape',data.shape)\n",
    "print('unique labels', data.Label.unique())\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "limited-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(673, 8)\n",
      "(673,)\n"
     ]
    }
   ],
   "source": [
    "# filter out records without desired labels\n",
    "data_MITNUC = data.loc[data['Label'].isin(['MIT','NUC'])].values\n",
    "\n",
    "# split data into features and target, encode target classes as 0 or 1\n",
    "X = data_MITNUC[:,:8]\n",
    "y = LabelEncoder().fit_transform(data_MITNUC[:,-1])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "regulation-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 8)\n",
      "(200,)\n",
      "(473, 8)\n",
      "(473,)\n"
     ]
    }
   ],
   "source": [
    "# split data into first 200 records and remainder\n",
    "n_l = 200\n",
    "\n",
    "Xk = X[:n_l,:]\n",
    "Yk = y[:n_l]\n",
    "Xu = X[n_l:,:]\n",
    "Yu = y[n_l:]\n",
    "\n",
    "print(Xk.shape)\n",
    "print(Yk.shape)\n",
    "print(Xu.shape)\n",
    "print(Yu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-reason",
   "metadata": {},
   "source": [
    "# 1.1. Part 1 (5 points)\n",
    "**TODO:**\n",
    "- **Let's first construct the weight matrix W.**\n",
    "- **Use $t = 0$ and $\\sigma$ as the standard deviation of $X$.**\n",
    "- **Then calculate the $D$ matrix and the Laplacian matrix (Delta).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-corruption",
   "metadata": {},
   "source": [
    "### Formulas\n",
    "Similarity is measured using the radial basis function (RBF):\n",
    "\n",
    "$$w_{ij}=\\exp{\\left( -\\sum_{d=1}^m \\frac{(x_{id} - x_{jd})^2}{\\sigma^2_d} \\right)}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "where\n",
    "- $x_i \\in \\mathbb{R}^m$\n",
    "- $x_{id}$ is the $d$-th component  of instance $x_i$\n",
    "- $\\sigma_1, \\ldots ,\\sigma_m$ are length scale hyperparameters for each dimension\n",
    "\n",
    "\n",
    "Note: $\\sum_{d=1}^m \\left( x_{id} - x_{jd} \\right)^2$ is the squared Euclidean distance between $x_i$ and $x_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "regulation-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other paper\n",
    "# https://www.aaai.org/Papers/ICML/2003/ICML03-118.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-white",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Laplacian_matrix(X):\n",
    "    ## TODO ##\n",
    "    \n",
    "    return Delta\n",
    "\n",
    "Delta = Laplacian_matrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-vietnam",
   "metadata": {},
   "source": [
    "# 1.2. Part 2 (5 points) \n",
    "**TODO:**\n",
    "- **Now complete the subroutine to compute the minimum-energy solution for the unlabeled instances. (Hint: Use the formula in page 38, Lecture 7.)** \n",
    "- **The function also outputs one submatrix that we will use to select points to query.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_energy_solution(Delta,n_l,fl):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Delta: The Laplacian matrix. \n",
    "        n_l: Number of labeled points. Notice that Delta should have the upper left submatrix \n",
    "            corresponding to these n_l points. So when new points get labeled, you may need \n",
    "            to rearrange the matrix.\n",
    "        fl: Known labels.\n",
    "    Returns:\n",
    "        Delta_uu_inv: Inverse matrix of the submatrix corresponding to unlabeled points.\n",
    "        fu: Minimum energy solution of all unlabeled points.\n",
    "    \"\"\"\n",
    "    ## TODO ##\n",
    "    \n",
    "    return Delta_uu_inv, fu\n",
    "\n",
    "Delta_uu_inv, fu = minimum_energy_solution(Delta,n_l,Yk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-discrimination",
   "metadata": {},
   "source": [
    "# 1.3. Part 3 (15 points) \n",
    "**TODO:**\n",
    "- **We would like to query the points that minimize the expected risk. To do so, we want to be able to calculate the expected estimated risk after querying any point $k$.**\n",
    "- **The variable `Rhat_fplus_xk` refers to $\\hat{R}(f^{+x_k})$.**\n",
    "- **`fu_xk0` is $f_u^{+(x_k,0)}$ and vice versa for `fu_xk1`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-growing",
   "metadata": {},
   "source": [
    "I'm confused about the notation involved in calculating expected risk for ZLG. In the paper, we have the following equations:\n",
    "\n",
    "#### Expected risk:\n",
    "\n",
    "$$\\hat{R}\\left( f^{+(x_k,y_k)} \\right)=\\sum_{i=1}^n min\\left( f_i^{+(x_k,y_k)},1-f_i^{+(x_k,y_k)}\\right)$$\n",
    "\n",
    "#### Expected estimated risk:\n",
    "\n",
    "$$\\hat{R}\\left( f^{+x_k} \\right)=\n",
    "(1-f_k)\\hat{R}\\left( f^{+(x_k,0)} \\right)\n",
    "+   f_k\\hat{R}\\left( f^{+(x_k,1)} \\right)$$\n",
    "\n",
    "\n",
    "#### Conditional Distribution of all unlabeled nodes:\n",
    "\n",
    "$$f_u^{+(x_k,y_k)}=f_u+(y_k-f_k)\\frac{(\\Delta_{uu}^{-1})_{ \\cdot k}}{(\\Delta_{uu}^{-1})_{kk}}$$\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "I'm confused at the difference between $f_u$ and $f$ and $f_i$. The paper defines $f=\\begin{bmatrix}f_l \\\\ f_u\\end{bmatrix}$ but I don't understand how exactly this works through the equations above. My understanding is that $f_u$ is a vector. I calculated that $f_u^{+(x_k,0)}$ is a vector of the same dimension.  \n",
    "\n",
    "Is $f^{+(x_k,0)}$ the same as $f_u^{+(x_k,0)}$?\n",
    "\n",
    "***\n",
    "\n",
    "I'm also confused at how to calculate estimated risk.\n",
    "\n",
    "$$\\hat{R}\\left( f^{+(x_k,0)} \\right)=\\sum_{i=1}^n min\\left( f_i^{+(x_k,0)},1-f_i^{+(x_k,0)}\\right)$$\n",
    "\n",
    "What is the $n$ in this case? I thought we were dealing with $f_u$. What would $f_1, f_2, \\ldots, f_n$ be?\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_estimated_risk(Delta_uu_inv,k,fu):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Delta_uu_inv: Inverse matrix of the submatrix corresponding to unlabeled points.\n",
    "        k: index of one unlabeled point with respect to the uu submatrix (not the entire Delta)\n",
    "        fu: Minimum energy solution of all unlabeled points.\n",
    "    Returns:\n",
    "        Rhat_fplus_xk: Expected estimated risk after querying node k\n",
    "    \"\"\"\n",
    "    ## fu plus xk, yk = 0\n",
    "    fu_xk0 = fu + (0 - fu[k])*Delta_uu_inv[:,k]/Delta_uu_inv[k,k]\n",
    "    ## fu plus xk, yk = 1\n",
    "    fu_xk1 = fu + (1 - fu[k])*Delta_uu_inv[:,k]/Delta_uu_inv[k,k]\n",
    "    \n",
    "    ## TODO ##\n",
    "    \n",
    "    return Rhat_fplus_xk\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-korea",
   "metadata": {},
   "source": [
    "# 1.4. Part 4 (5 points) \n",
    "**TODO:**\n",
    "- **Compute the above expected estimated risk for all unlabeled points and select one to query.**\n",
    "- **Let's try query 100 points. Which points are queried? Compare with random queries and make a plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zlg_query(Delta_uu_inv,n_l,fu,n_samples):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Delta_uu_inv: Inverse matrix of the submatrix corresponding to unlabeled points.\n",
    "        n_l: Number of labeled points.\n",
    "        fu: Minimum energy solution of all unlabeled points.\n",
    "        n_samples: Number of samples.\n",
    "    Returns:\n",
    "        query_idx: the idx of the point to query, wrt the unlabeled points \n",
    "                (idx is 0 if it's the first unlabeled point)\n",
    "    \"\"\"\n",
    "    n_u = n_samples - n_l\n",
    "    query_idx = 0\n",
    "    min_Rhat = np.inf\n",
    "    ## TODO ##\n",
    "    \n",
    "    return query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.shape[0]\n",
    "for t in range(100):\n",
    "    ## edit this block ##\n",
    "    query_idx = zlg_query(Delta_uu_inv,n_l,fu,n_samples)\n",
    "    Yk = np.append(Yk,Yu[query_idx])\n",
    "    Yu = np.delete(Yu,query_idx)\n",
    "    Xk = np.append(Xk,[Xu[query_idx,:]],axis=0)\n",
    "    Xu = np.delete(Xu,query_idx, 0)\n",
    "    n_l += 1\n",
    "    Delta = Laplacian_matrix(np.concatenate((Xk,Xu),axis=0))\n",
    "    Delta_uu_inv, fu = minimum_energy_solution(Delta,n_l,Yk)\n",
    "    print(query_idx)\n",
    "    ## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-manchester",
   "metadata": {},
   "source": [
    "# 1.5. Bonus question \n",
    "\n",
    "**Answer the following questions. (Your grade will not exceed 100 for this homework.)**\n",
    "\n",
    "#### 1. For this dataset, how many labeled data points do you actually need to train the model sufficiently well? \n",
    "#### 2. And why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
