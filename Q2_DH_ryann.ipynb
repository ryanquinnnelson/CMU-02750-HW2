{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blessed-visibility",
   "metadata": {},
   "source": [
    "# Question 2: DH algorithm (50 points)\n",
    "**In this question we are going to implement the DH algorithm according to the paper https://icml.cc/Conferences/2008/papers/324.pdf and try to predict protein localization sites in Eukaryotic cells.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-maintenance",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "prospective-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import choice\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "# provided custom modules\n",
    "from provided.update_empirical import update_empirical\n",
    "from provided.best_pruning_and_labeling import best_pruning_and_labeling\n",
    "from provided.assign_labels import assign_labels\n",
    "from provided.get_leaves import get_leaves\n",
    "\n",
    "\n",
    "# setup\n",
    "seed = 2021\n",
    "warnings. filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-nerve",
   "metadata": {},
   "source": [
    "## Part 2.0 Data loading and hierarchical clustering\n",
    "**The DH algorithm is based on hierarchical clustering of the dataset. We will use the DH algorithm on this classification problem: [Protein Localization Prediction](https://archive.ics.uci.edu/ml/datasets/Yeast).**\n",
    "\n",
    "**The first step is to load the dataset and conduct a hierarchical clustring using the `Scipy` package. This part has been implemented, read through the code to make sure you understand what is being done.**\n",
    "\n",
    "**NOTES:**\n",
    "- **X_train: data matrix 1200x8**\n",
    "- **Y_train: true labels 1200x1**\n",
    "- **X_test: data matrix 284x8**\n",
    "- **Y_test: true labels 284x1**\n",
    "\n",
    "**TIPS:**\n",
    "- **Check out this [link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html) for details about hierarchical clustering.**\n",
    "- **If you are unfamiliar with hierarchical clustering using scipy, [this](https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/ ) is another helpful resource. (We won't use dendrograms here, but he gives a nice explanation of how to interpret the linkage matrix).**\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-dominant",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "driven-recommendation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2    X3    X4   X5   X6    X7    X8 Label\n",
       "0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n",
       "1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n",
       "2  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n",
       "3  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n",
       "4  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv('data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "boring-salad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['MIT', 'NUC'], dtype=object), array([244, 429]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.Label, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-pottery",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train, y_train, X_test, y_test, T = load_data('data/data.csv', seed=seed, filter_class=['MIT', 'NUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-marketing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-walker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-suite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "virgin-desert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2    X3    X4   X5  X6    X7    X8 Label\n",
       "0  0.58  0.61  0.47  0.13  0.5   0  0.48  0.22   MIT\n",
       "1  0.43  0.67  0.48  0.27  0.5   0  0.53  0.22   MIT\n",
       "2  0.64  0.62  0.49  0.15  0.5   0  0.53  0.22   MIT\n",
       "3  0.58  0.44  0.57  0.13  0.5   0  0.54  0.22   NUC\n",
       "4  0.58  0.44  0.57  0.13  0.5   0  0.54  0.22   MIB"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/testdata.csv')\n",
    "df = df[:5]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "variable-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MIT', 'NUC']\n",
      "mask before\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: Label, dtype: bool\n",
      "\n",
      "mask after\n",
      "0     True\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "Name: Label, dtype: bool\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2    X3    X4   X5  X6    X7    X8 Label\n",
       "0  0.58  0.61  0.47  0.13  0.5   0  0.48  0.22   MIT\n",
       "1  0.43  0.67  0.48  0.27  0.5   0  0.53  0.22   MIT\n",
       "2  0.64  0.62  0.49  0.15  0.5   0  0.53  0.22   MIT\n",
       "3  0.58  0.44  0.57  0.13  0.5   0  0.54  0.22   NUC\n",
       "4  0.58  0.44  0.57  0.13  0.5   0  0.54  0.22   MIB"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_class = ['MIT','NUC']\n",
    "print(filter_class)\n",
    "mask = df.Label == 0\n",
    "print('mask before')\n",
    "print(mask)\n",
    "print()\n",
    "for x in filter_class:\n",
    "#     print(x)\n",
    "#     print(df.Label == x)\n",
    "#     print()\n",
    "    mask = mask | (df.Label == x)\n",
    "print('mask after')\n",
    "print(mask)\n",
    "print()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "understood-comedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2    X3    X4   X5  X6    X7    X8 Label\n",
       "0  0.58  0.61  0.47  0.13  0.5   0  0.48  0.22   MIT\n",
       "1  0.43  0.67  0.48  0.27  0.5   0  0.53  0.22   MIT\n",
       "2  0.64  0.62  0.49  0.15  0.5   0  0.53  0.22   MIT\n",
       "3  0.58  0.44  0.57  0.13  0.5   0  0.54  0.22   NUC"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[mask]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "proved-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# \n",
    "X = df.iloc[:, :8].to_numpy()\n",
    "print(X.shape)\n",
    "#\n",
    "y = df.Label.astype('category').cat.codes.to_numpy()\n",
    "print(y.shape)\n",
    "\n",
    "#\n",
    "# X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "a = X.astype('float')\n",
    "a.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "retained-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[0.58 0.61 0.47 0.13 0.5  0.   0.48 0.22]\n",
      " [0.43 0.67 0.48 0.27 0.5  0.   0.53 0.22]\n",
      " [0.64 0.62 0.49 0.15 0.5  0.   0.53 0.22]\n",
      " [0.58 0.44 0.57 0.13 0.5  0.   0.54 0.22]]\n",
      "\n",
      "[[0.         2.         0.083666   2.        ]\n",
      " [3.         4.         0.23366643 3.        ]\n",
      " [1.         5.         0.30149627 4.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "n_samples = len(X)\n",
    "print(n_samples)\n",
    "print(X)\n",
    "print()\n",
    "Z = linkage(X, method='ward')\n",
    "print(Z)\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "dn = dendrogram(Z)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "canadian-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [3, 4],\n",
       "       [1, 5]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = Z[:, :2].astype(int)\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "frequent-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "consolidated-screen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtree_sizes = np.zeros(link[-1, -1] + 2)\n",
    "print(subtree_sizes)\n",
    "subtree_sizes[:n_samples] = 1\n",
    "subtree_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "molecular-tiger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 0}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent = {}\n",
    "parent[2 * (n_samples - 1)] = 0  # set root node as 0\n",
    "parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "proud-player",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left 0\n",
      "right 2\n",
      "parent 4\n",
      "left 3\n",
      "right 4\n",
      "parent 5\n",
      "left 1\n",
      "right 5\n",
      "parent 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(link)):\n",
    "    left = link[i, 0]\n",
    "    print('left',left)\n",
    "    right = link[i, 1]\n",
    "    print('right',right)\n",
    "    current = i + n_samples\n",
    "    print('parent',current)\n",
    "    subtree_sizes[current] = subtree_sizes[left] + subtree_sizes[right]\n",
    "    parent[left] = current\n",
    "    parent[right] = current\n",
    "    \n",
    "parent\n",
    "subtree_sizes\n",
    "\n",
    "# T = [link, subtree_sizes, parent]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-contrary",
   "metadata": {},
   "source": [
    "# Part 2.0.1 Supervised classification methods.\n",
    "**TODO:**\n",
    "- **Initialize a classifier**\n",
    "\n",
    "**We provide several classifiers that can be used. Choose your favourite one. To use the Neural Network classifier, you need to install [pytorch](https://pytorch.org/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "## Random Forest\n",
    "N_estimator_rf = 20\n",
    "MAX_depth_rf = 6\n",
    "rf = RandomForestClassifier(n_estimators = N_estimator_rf, \n",
    "                            max_depth = MAX_depth_rf, random_state = seed)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "## Gradient Boosting Decision Tree\n",
    "N_estimator_gbdt = 20\n",
    "gbdt_max_depth = 6\n",
    "gbdt = GradientBoostingClassifier(n_estimators = N_estimator_gbdt,\n",
    "                                 learning_rate = 0.1,\n",
    "                                 max_depth = gbdt_max_depth,\n",
    "                                 random_state = seed)\n",
    "gbdt.fit(X_train,y_train)\n",
    "\n",
    "## 3-Layer fully connected NN\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "class NNClassifier(object):\n",
    "    def __init__(self,\n",
    "                 feature_n,\n",
    "                 class_n,\n",
    "                 hidden_n = 30,\n",
    "                 learning_rate = 4e-3,\n",
    "                 weight_decay = 1e-5):\n",
    "        self.model = torch.nn.Sequential(torch.nn.Linear(feature_n,hidden_n),\n",
    "                                        torch.nn.SiLU(),\n",
    "                                        torch.nn.Linear(hidden_n,hidden_n),\n",
    "                                        torch.nn.SiLU(),\n",
    "                                        torch.nn.Linear(hidden_n,class_n))\n",
    "        self.lr = learning_rate\n",
    "        self.wd = weight_decay\n",
    "    def fit(self,X_train,y_train,epoches = 300,batch_size = 50):\n",
    "        X_t = torch.from_numpy(X_train.astype(np.float32))\n",
    "        y_t = torch.from_numpy(y_train.astype(np.int64))\n",
    "        dataset = TensorDataset(X_t,y_t)\n",
    "        loader = DataLoader(dataset,batch_size = batch_size,shuffle = True)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(reduction = 'mean')\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr,weight_decay=self.wd)\n",
    "        loss_record = 0.0\n",
    "        report_epoch = 50\n",
    "        for epoch_i in range(epoches):\n",
    "            for batch in loader:\n",
    "                x_batch,y_batch = batch\n",
    "                y_pred = self.model(x_batch)\n",
    "                loss = loss_fn(y_pred,y_batch)\n",
    "                self.model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_record += loss.item()\n",
    "            if epoch_i%report_epoch == report_epoch-1:\n",
    "                print(\"[%d|%d] epoch loss:%.2f\"%(epoch_i+1,epoches,loss_record/report_epoch))\n",
    "                loss_record = 0.0\n",
    "            if epoch_i>=epoches:\n",
    "                break\n",
    "    \n",
    "    def score(self,X_test,y_test):\n",
    "        X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "        y_pred_test = self.model(X_test_tensor)\n",
    "        y_output = torch.argmax(y_pred_test,axis = 1).numpy()\n",
    "        return (y_output == y_test).mean()\n",
    "        \n",
    "nn = NNClassifier(feature_n = X_train.shape[1],class_n = len(np.unique(y_train)))\n",
    "nn.fit(X_train,y_train)\n",
    "\n",
    "## Accuracy of 4 classifiers.\n",
    "print('Accuracy of logistic regression: \\t{:.3f}'.format(lr.score(X_test,y_test)))\n",
    "print('Accuracy of random forest: \\t\\t{:.3f}'.format(rf.score(X_test,y_test)))\n",
    "print('Accuracy of Gradient Boosting Decision Tree: \\t\\t{:.3f}'.format(gbdt.score(X_test,y_test)))\n",
    "print('Accuracy of Neural Network: \\t\\t{:.3f}'.format(nn.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-transcript",
   "metadata": {},
   "source": [
    "### Choose and initialize your classifier:\n",
    "The classifier is going to be used in 2.2, the choose of classifier won't influence your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Uncomment one line to choose your classifier.\n",
    "#classifier = LogisticRegression()\n",
    "\n",
    "#classifier = RandomForestClassifier(n_estimators = N_estimator_rf,max_depth = MAX_depth_rf, random_state = seed)\n",
    "\n",
    "#classifier = GradientBoostingClassifier(n_estimators = N_estimator_gbdt,\n",
    "#                                 learning_rate = 0.1,\n",
    "#                                 max_depth = gbdt_max_depth,\n",
    "#                                 random_state = seed)\n",
    "\n",
    "#classifier = NNClassifier(feature_n = X_train.shape[1],class_n = len(np.unique(y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-ribbon",
   "metadata": {},
   "source": [
    "## Part 2.1 Implement DH algorithm (Hierarchical Sampling for Active Learning). (30 points)\n",
    "\n",
    "**TODO:**\n",
    "- **Please complete the functions to implement the DH algorithm and run the active learning algorithm on the training dataset.**\n",
    "- **The utils functions has been implemented and attached in the homework folder, including `update_empirical.py`, `best_pruning_and_labeling.py`, `assign_labels.py`, and `get_leaves.py`. Please read them and finish the following functions to implement the DH algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-simpson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(L,labels):\n",
    "    \"\"\"Compute the error\n",
    "\n",
    "    :param L: labeling of leaf nodes\n",
    "    :param labels: true labels of each node\n",
    "\n",
    "    :returns error: error of predictions\"\"\"\n",
    "\n",
    "    wrong = 0\n",
    "    wrong = (L[:len(labels)]!=labels).sum()\n",
    "    error = wrong/len(labels)\n",
    "    return error\n",
    "\n",
    "def select_case_1(data,labels,T,budget,batch_size):\n",
    "    \"\"\"DH algorithm where we choose P proportional to the size of subtree rooted at each node\n",
    "\n",
    "    :param data: Data matrix 1200x8\n",
    "    :param labels: true labels 1200x1\n",
    "    :param T: 3 element tree\n",
    "        T[0] = linkage matrix from hierarchical clustering.  See https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "               for details. If you are unfamiliar with hierarchical clustering using scipy, the following is another helpful resource (We won't use dendrograms\n",
    "               here, but he gives a nice explanation of how to interpret the linkage matrix):\n",
    "               https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/ \n",
    "\n",
    "        T[1] = An array denoting the size of each subtree rooted at node i, where i indexes the array.  \n",
    "               ie. The number of all children + grandchildren + ... + the node itself\n",
    "\n",
    "        T[2] = dict where keys are nodes and values are the node's parent\n",
    "    :param budget: Number of iterations to make \n",
    "    :param batch_size: Number of queries per iteration\"\"\"\n",
    "\n",
    "    n_nodes = len(T[1]) #total nodes in T\n",
    "    n_samples = len(data) #total samples in data\n",
    "    L = np.zeros(n_nodes) #majority label\n",
    "    p1 = np.zeros(n_nodes) #empirical label frequency\n",
    "    n = np.zeros(n_nodes) #number of points sampled from each node\n",
    "    error = []#np.zeros(n_samples) #error at each round\n",
    "    root = n_nodes-1 #corresponds to index of root\n",
    "    P = np.array([root])\n",
    "    L[root] = 1    \n",
    "    \n",
    "    for i in range(budget):\n",
    "        selected_P = []\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            #TODO: select a node from P proportional to the size of subtree rooted at each node\n",
    "            raise(NotImplemetedError)\n",
    "            \n",
    "            ##TODO: pick a random leaf node from subtree Tv and query its label\n",
    "\n",
    "            #TODO: update empirical counts and probabilities for all nodes u on path from z to v\n",
    "\n",
    "        for p in selected_P:\n",
    "            #TODO: update admissible A and compute scores; find best pruning and labeling\n",
    "            raise(NotImplemetedError)\n",
    "            #TODO: update pruning P and labeling L\n",
    "\n",
    "        #TODO: temporarily assign labels to every leaf and compute error\n",
    "        L_temp = L.copy()\n",
    "        raise(NotImplemetedError)\n",
    "\n",
    "    for i in range(len(P)):\n",
    "        L = assign_labels(L,P[i],P[i],T,n_samples)\n",
    "    \n",
    "    return L, np.array(error)\n",
    "\n",
    "def select_case_2(data,labels,T,budget,batch_size):\n",
    "    \"\"\"DH algorithm where we choose P by biasing towards choosing nodes in areas where the observed labels are less pure\n",
    "\n",
    "    :param data: Data matrix 1200x8\n",
    "    :param labels: true labels 284x1\n",
    "    :param T: 3 element tree\n",
    "        T[0] = linkage matrix from hierarchical clustering.  See https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "               for details. If you are unfamiliar with hierarchical clustering using scipy, the following is another helpful resource (We won't use dendrograms\n",
    "               here, but he gives a nice explanation of how to interpret the linkage matrix):\n",
    "               https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/ \n",
    "\n",
    "        T[1] = An array denoting the size of each subtree rooted at node i, where i indexes the array.  \n",
    "               ie. The number of all children + grandchildren + ... + the node itself\n",
    "\n",
    "        T[2] = dict where keys are nodes and values are the node's parent\n",
    "    :param budget: Number of iterations to make \n",
    "    :param batch_size: Number of queries per iteration\"\"\"\n",
    "\n",
    "    n_nodes = len(T[1]) #total nodes in T\n",
    "    n_samples = len(data) #total samples in data\n",
    "    L = np.zeros(n_nodes,dtype = int) #majority label\n",
    "    p1 = np.zeros(n_nodes) #empirical label frequency\n",
    "    n = np.zeros(n_nodes) #number of points sampled from each node\n",
    "    error = []#np.zeros(n_samples) #error at each round\n",
    "    root = n_nodes-1 #corresponds to index of root\n",
    "    P = np.array([root])\n",
    "    L[root] = 1    \n",
    "\n",
    "    for i in range(budget):\n",
    "        selected_P = []\n",
    "        for b in range(batch_size):\n",
    "            #TODO: select a node from P biasing towards choosing nodes in areas where the observed labels are less pure\n",
    "            raise(NotImplemetedError)\n",
    "            \n",
    "            #TODO: pick a random leaf node from subtree Tv and query its label\n",
    "\n",
    "            #TODO: update empirical counts and probabilities for all nodes u on path from z to v\n",
    "\n",
    "        for p in selected_P:\n",
    "            #TODO: update admissible A and compute scores; find best pruning and labeling\n",
    "            raise(NotImplemetedError)\n",
    "            #TODO: update pruning P and labeling L\n",
    "\n",
    "        #TODO: temporarily assign labels to every leaf and compute error\n",
    "        L_temp = L.copy()\n",
    "        raise(NotImplemetedError)\n",
    "        \n",
    "    for i in range(len(P)):\n",
    "        L = assign_labels(L,P[i],P[i],T,n_samples)\n",
    "        \n",
    "    return L, np.array(error)                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-graph",
   "metadata": {},
   "source": [
    "## Part 2.2 Run the sample code (10 points)\n",
    "**TODO:**\n",
    "- **Run the following sample code and compare the two figures.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_DH(part,clf,budget):\n",
    "    \"\"\"Main function to run all your code once complete.  After you complete\n",
    "       select_case_1() and select_case_2(), this will run the DH algo for each \n",
    "       dataset and generate the plots you will submit within your write-up.\n",
    "\n",
    "       :param part: which part of the homework to run\n",
    "       :param clf: The classifier used to predcit on the dataset.\n",
    "       :param budget: The number of times that one can query a label from the oracle.\n",
    "    \"\"\"\n",
    "    \n",
    "    part = part.lower()\n",
    "    num_trials = 5\n",
    "    batch_size = 10\n",
    "    clf2 = copy.deepcopy(clf)\n",
    "    axs = plt.subplot()\n",
    "    if part == \"b\":\n",
    "        print(\"Running part B\")\n",
    "        X_train, y_train, X_test, y_test, T = load_data()\n",
    "        l = np.zeros(budget)\n",
    "        for i in range(num_trials):\n",
    "            print(\"Currently on iteration {}\".format(i))\n",
    "            L, error = select_case_1(X_train,y_train,T,budget,batch_size)\n",
    "            l += error \n",
    "        l /= num_trials\n",
    "        \n",
    "        ## TODO: train the classifier clf on the predicted label.\n",
    "        #raise(NotImplementedError)\n",
    "        clf.fit(X_train,L[:len(X_train)])\n",
    "        \n",
    "        print('Accuracy of classifier trained on random sampling dataset: \\t{:.3f}'.format(clf.score(X_test,y_test)))\n",
    "        axs.plot(np.arange(budget),l,label = \"Random sampling\")\n",
    "\n",
    "    elif part == \"c\":\n",
    "        print(\"Running part C\")\n",
    "        X_train, y_train, X_test, y_test, T = load_data()\n",
    "        l = np.zeros(budget)\n",
    "        for i in range(num_trials):\n",
    "            print(\"Currently on iteration {}\".format(i))\n",
    "            L, error = select_case_2(X_train,y_train,T,budget,batch_size)\n",
    "            l += error \n",
    "        l /= num_trials\n",
    "        \n",
    "        ## TODO: train the classifier clf2 on the predicted label.\n",
    "        #raise(NotImplementedError)\n",
    "        clf2.fit(X_train,L[:len(X_train)])\n",
    "        \n",
    "        print('Accuracy of classifier trained on active learning dataset: \\t{:.3f}'.format(clf2.score(X_test,y_test)))\n",
    "        axs.plot(np.arange(budget),l,label = \"Active learning\")\n",
    "\n",
    "    else:\n",
    "        print(\"Incorrect part provided. Either 'b', 'c', 'd', or 'e' expected\")\n",
    "    axs.set_ylim([0,0.5])\n",
    "    axs.set_xlabel(\"Number of query samples\")\n",
    "    axs.set_ylabel(\"Error rate\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"q2_2.png\")\n",
    "BUDGET = 200 #You can change this number to a smaller one during testing.\n",
    "for part in \"bc\":\n",
    "    call_DH(part,classifier,BUDGET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-majority",
   "metadata": {},
   "source": [
    "## Part 2.3 Questions (10 points):\n",
    "**TODO:**\n",
    "- **Answer the following questions.**\n",
    "### What is a \"admissible pair\" according to the paper (5 points)?\n",
    "### Please explain the sampling bias that is dealt with in the DH algorithm and why it would be a problem if we just query the unlabeled point which is closest to the decision boundary (5 points)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
